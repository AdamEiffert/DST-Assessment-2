---
title: "05-Baseline"
output: html_document
---

# Baseline Model

We have decided to use a default random forest model as our baseline model. Here we will train and test the model, however the comparison to the complex model is found in 06-Complex. 

### Load Libraries
```{r}
if (!require("googledrive")) install.packages("googledrive")
library("googledrive")
library("data.table")
library("caret")
if (!require("randomForest")) install.packages("randomForest")
library("randomForest")
library("R.utils")
if (!require("mltools")) install.packages("mltools")
library("mltools")
if (!require("PRROC")) install.packages("PRROC")
library("PRROC")
if (!require("bit64")) install.packages("bit64")
library("bit64")
if (!require("InformationValue")) install.packages("InformationValue")
library("InformationValue")
```
In case the previous code from the project has not been run, we have linked to a Google drive document to train the model.
```{r}
if (!file.exists('../data/processed/labelled_clean.csv')) {
  drive_deauth()
  drive_download(as_id("1xRCcAp6NjU8SD80nCYybKdU9jv2TgPgv"), path = "../data/processed/labelled_clean.csv", overwrite = TRUE)
}
set.seed(63)
df <- fread('../data/processed/labelled_clean.csv')[,- 1] # download from google drive when confident in csv
```

Originally we planned to do a 10-fold over the training data, however each instance of randomForest took a couple of hours at a time and so it took too long to train. As such we trained using the 70%. A 70/30 training/testing split is quite commonly used as is provides a reasonable balance between being able to train an effective model while being able to test the model to a reasonable efficay. 
```{r}
sample <- createDataPartition(df$malicious, p = 0.7, list = FALSE)
train <- df[sample,]
test <- df[-sample,]
model <- randomForest(train[,- 'malicious'], unlist(train[,'malicious']))
```
Now that we have trained the model, we can use it to predict the results of the test data. The predict function provides numeric values between 0 and 1 and so in order to make these categorical I have split the information at 0.5.

```{r}
prediction <- predict(model,test[,-'malicious'])
prediction[prediction < 0.5] = 0
prediction[prediction > 0.5] = 1
```
Here we look at the specificity and the sensitivity of the predictions. We will compare these values to the complex model in 06-complex.
```{R}
specificity(test$malicious,prediction)
sensitivity(test$malicious,prediction)
```